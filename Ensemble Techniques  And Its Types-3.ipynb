{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad64a40-9151-4fdc-982d-fdc7ccf14e34",
   "metadata": {},
   "source": [
    "## ‚ùì Q1. What is Random Forest Regressor?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "A **Random Forest Regressor** is an ensemble machine learning algorithm that combines multiple **decision trees** to make more accurate and stable predictions for **regression tasks** (predicting continuous numerical values).\n",
    "\n",
    "It belongs to the **bagging (Bootstrap Aggregation)** family of ensemble techniques. The model creates a \"forest\" of decision trees where each tree is trained on a random subset of the data (with replacement) and a random subset of the features. The final prediction is the **average** of all individual tree predictions.\n",
    "\n",
    "### üîç Key Characteristics:\n",
    "\n",
    "* Reduces **overfitting** compared to a single decision tree.\n",
    "* Handles large datasets and high dimensionality well.\n",
    "* Can measure feature importance.\n",
    "* Works well even when some data is missing or noisy.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Visual Intuition (Optional):\n",
    "\n",
    "Imagine you ask 100 different experts to estimate the price of a house. Each expert gives a slightly different answer based on their own experience (a subset of data/features). Averaging their opinions often leads to a more reliable prediction ‚Äî that's the idea behind a Random Forest Regressor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69a984d-b56a-4eb9-b41a-87c9ceb28406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.26\n"
     ]
    }
   ],
   "source": [
    "###  Example\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load sample data\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510e48a-17fd-416b-bbf6-cdc83f17a7aa",
   "metadata": {},
   "source": [
    "## ‚ùì Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "The **Random Forest Regressor** reduces the risk of overfitting primarily through **ensemble learning and randomness**. It addresses overfitting in the following key ways:\n",
    "\n",
    "---\n",
    "\n",
    "### üå≥ 1. **Bagging (Bootstrap Aggregation)**\n",
    "\n",
    "* Each decision tree is trained on a **random subset of the training data**, drawn with replacement.\n",
    "* This means that each tree sees a slightly different view of the data, leading to **diverse models**.\n",
    "* The final prediction is an **average** of all tree outputs, which reduces the variance that individual trees might have.\n",
    "\n",
    "---\n",
    "\n",
    "### üé≤ 2. **Feature Randomness**\n",
    "\n",
    "* At each split in a tree, only a **random subset of features** is considered.\n",
    "* This reduces the likelihood that all trees make the same splits and follow the same patterns.\n",
    "* It encourages **decorrelation** between the trees, making the ensemble more robust.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öñÔ∏è 3. **Averaging Reduces Variance**\n",
    "\n",
    "* While a single deep decision tree is prone to overfitting (low bias, high variance), combining many such trees by **averaging** their outputs **lowers the overall variance** of the model.\n",
    "* The model becomes more **generalizable** to unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cacb41d-8e04-4650-9eb5-0001c1799bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 11078.278034632134\n",
      "Random Forest MSE: 4230.596468900218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate sample data\n",
    "X, y = make_regression(n_samples=500, n_features=10, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Single decision tree (prone to overfitting)\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Compare performance\n",
    "print(\"Decision Tree MSE:\", mean_squared_error(y_test, y_pred_dt))\n",
    "print(\"Random Forest MSE:\", mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef010311-edeb-4fa3-a6da-66174eb7cf2a",
   "metadata": {},
   "source": [
    "> You‚Äôll typically see that the **Random Forest has a lower Mean Squared Error**, showing better generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary:\n",
    "\n",
    "Random Forest combats overfitting by:\n",
    "\n",
    "* Training on random subsets of data and features.\n",
    "* Aggregating predictions to smooth out noise.\n",
    "* Encouraging model diversity, which leads to **more stable and generalized predictions**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cded8-c15c-4cfe-90cf-59b6cd7b6a8b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚ùì Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "In a **Random Forest Regressor**, the final prediction is made by **aggregating the outputs** of all individual decision trees in the forest using **averaging**.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ How It Works:\n",
    "\n",
    "1. Each tree in the forest is trained independently on a different random subset of the data (bagging).\n",
    "2. For a given input sample, each tree makes its own **regression prediction** (a numerical value).\n",
    "3. The Random Forest Regressor **collects all predictions** from the trees.\n",
    "4. The final output is the **mean (average)** of all these predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Formula (Conceptual):\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{N} \\sum_{i=1}^{N} y_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\hat{y}$ is the final predicted value,\n",
    "* $N$ is the number of trees in the forest,\n",
    "* $y_i$ is the prediction from the $i$-th tree.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Why Averaging Works:\n",
    "\n",
    "* It **reduces variance** by smoothing out the predictions.\n",
    "* If some trees make errors due to noise or overfitting on their subset, those errors are **diluted** by the ensemble.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878127f5-016f-44e7-bd50-06b5fe6e82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual average matches model prediction: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate dataset\n",
    "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf = RandomForestRegressor(n_estimators=3, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions from each tree\n",
    "all_tree_preds = [tree.predict(X_test) for tree in rf.estimators_]\n",
    "\n",
    "# Aggregate by averaging manually\n",
    "avg_pred = np.mean(all_tree_preds, axis=0)\n",
    "\n",
    "# Compare with model's prediction\n",
    "model_pred = rf.predict(X_test)\n",
    "\n",
    "# Check if they match\n",
    "print(\"Manual average matches model prediction:\", np.allclose(avg_pred, model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b80c97-d89d-43ce-8aa9-f75ba0b97423",
   "metadata": {},
   "source": [
    "### ‚úÖ Summary:\n",
    "\n",
    "The Random Forest Regressor **aggregates predictions by averaging** the outputs of its decision trees, resulting in a more stable and accurate prediction than any single tree could provide.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2392a2f-b980-4cea-8b07-32746b221c32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "A **Random Forest Regressor** in `scikit-learn` has several hyperparameters that control the behavior of the ensemble, how trees are built, and how predictions are aggregated. These hyperparameters can significantly affect model performance and training time.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Key Hyperparameters:\n",
    "\n",
    "| Hyperparameter      | Description                                                                                                                                     |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `n_estimators`      | Number of trees in the forest. More trees usually improve performance but increase training time. *(default: 100)*                              |\n",
    "| `max_depth`         | Maximum depth of each decision tree. Controls overfitting. *(default: None ‚Äî trees expand until pure or min samples reached)*                   |\n",
    "| `min_samples_split` | Minimum number of samples required to split an internal node. Higher values reduce overfitting.                                                 |\n",
    "| `min_samples_leaf`  | Minimum number of samples required to be at a leaf node. Prevents trees from learning too fine-grained patterns.                                |\n",
    "| `max_features`      | Number of features to consider when looking for the best split (`\"auto\"`, `\"sqrt\"`, `\"log2\"`, or integer). Controls randomness and performance. |\n",
    "| `bootstrap`         | Whether bootstrap samples are used when building trees. *(default: True)*                                                                       |\n",
    "| `oob_score`         | Whether to use out-of-bag samples to estimate the generalization accuracy. Useful for validation. *(default: False)*                            |\n",
    "| `random_state`      | Controls the randomness for reproducibility.                                                                                                    |\n",
    "| `n_jobs`            | Number of CPU cores to use. `-1` uses all cores. Speeds up training.                                                                            |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e472bc1-f15f-4dee-b761-f8f903c6e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7c05b-7545-4206-b3a2-21e297a23168",
   "metadata": {},
   "source": [
    "### üß† Tuning Tip:\n",
    "\n",
    "Use `GridSearchCV` or `RandomizedSearchCV` to tune hyperparameters for optimal performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db4b8b98-5863-4404-951d-6714163c71e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions={'max_depth': [10, 20, None],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_grid, n_iter=10, cv=5)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdbff0-d429-42f7-9ceb-dcea0d782f63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Summary:\n",
    "\n",
    "Hyperparameters in Random Forest Regressor control how each tree is built and how the forest as a whole behaves. Proper tuning is crucial for achieving good performance while avoiding overfitting or underfitting.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30daa72-8f1a-4410-82b9-9445e4a8ca5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "Both **Random Forest Regressor** and **Decision Tree Regressor** are machine learning models used for predicting continuous values. However, they differ significantly in how they operate and perform.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Key Differences:\n",
    "\n",
    "| Feature              | **Decision Tree Regressor**             | **Random Forest Regressor**                            |\n",
    "| -------------------- | --------------------------------------- | ------------------------------------------------------ |\n",
    "| **Model Type**       | Single tree                             | Ensemble of many trees                                 |\n",
    "| **Overfitting Risk** | High, especially with deep trees        | Lower, due to averaging multiple trees                 |\n",
    "| **Bias**             | Low                                     | Slightly higher than a deep tree                       |\n",
    "| **Variance**         | High                                    | Lower (reduced by ensemble averaging)                  |\n",
    "| **Stability**        | Sensitive to data changes               | More stable and robust                                 |\n",
    "| **Performance**      | Fast and interpretable, but can overfit | Generally more accurate and reliable                   |\n",
    "| **Interpretability** | Easy to interpret and visualize         | Harder to interpret as it's a collection of many trees |\n",
    "| **Training Time**    | Faster (only one tree)                  | Slower (many trees to train)                           |\n",
    "\n",
    "---\n",
    "\n",
    "### üå≤ Visual Intuition:\n",
    "\n",
    "* A **Decision Tree Regressor** can be seen as a single opinionated expert that memorizes the training data.\n",
    "* A **Random Forest Regressor** is like consulting 100 different experts (trees) and averaging their predictions ‚Äî leading to a more **balanced and generalized** result.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab409c32-835e-426a-88fe-1aa8d8f03b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 3020.24\n",
      "Random Forest MSE: 1125.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Dataset\n",
    "X, y = make_regression(n_samples=500, n_features=5, noise=15, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "mse_dt = mean_squared_error(y_test, dt.predict(X_test))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "mse_rf = mean_squared_error(y_test, rf.predict(X_test))\n",
    "\n",
    "print(f\"Decision Tree MSE: {mse_dt:.2f}\")\n",
    "print(f\"Random Forest MSE: {mse_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0285a-2528-4866-a619-6e62893c7393",
   "metadata": {},
   "source": [
    "You‚Äôll usually see that **Random Forest achieves a lower MSE** and performs better on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary:\n",
    "\n",
    "* Use **Decision Tree Regressor** for simpler, interpretable models.\n",
    "* Use **Random Forest Regressor** for higher accuracy, better generalization, and lower overfitting ‚Äî especially on complex datasets.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2895e-305e-4078-935a-d0999a234806",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "The **Random Forest Regressor** is a powerful ensemble method that often performs well on a wide range of regression tasks. However, like any algorithm, it comes with both strengths and limitations.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Advantages:\n",
    "\n",
    "| Advantage                              | Description                                                                                          |\n",
    "| -------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| **Reduces Overfitting**                | By averaging the predictions of many decision trees, it lowers variance and improves generalization. |\n",
    "| **Handles High Dimensional Data**      | Works well even when there are many features or complex feature interactions.                        |\n",
    "| **Robust to Noise and Outliers**       | Less sensitive to noisy data and outliers compared to individual decision trees.                     |\n",
    "| **Feature Importance**                 | Provides insights into which features are most influential in the predictions.                       |\n",
    "| **Works Without Feature Scaling**      | No need for normalization or standardization of features.                                            |\n",
    "| **Handles Missing Values (partially)** | Can maintain performance even if some data is missing or incomplete.                                 |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå Disadvantages:\n",
    "\n",
    "| Disadvantage                       | Description                                                                                                                                        |\n",
    "| ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Less Interpretable**             | Unlike a single decision tree, the model's inner workings are harder to interpret due to its complexity.                                           |\n",
    "| **Slower Training and Prediction** | Requires more computational resources since it builds and aggregates many trees.                                                                   |\n",
    "| **Large Memory Usage**             | More trees mean more memory is needed, especially with large datasets.                                                                             |\n",
    "| **Can Overfit with No Tuning**     | Although it reduces overfitting compared to decision trees, using too many deep trees or not tuning hyperparameters can still lead to overfitting. |\n",
    "| **Not Ideal for Extrapolation**    | Like most tree-based models, Random Forest performs poorly when predicting values outside the range seen in training data.                         |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Tip:\n",
    "\n",
    "Random Forest is often a **go-to baseline model** for regression tasks because of its balance of accuracy and robustness. However, for explainability or highly time-sensitive applications, simpler or more interpretable models may be preferred.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc3935-f63c-4e27-9586-d469c3996dd4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚ùì Q7. What is the output of Random Forest Regressor?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "The **output of a Random Forest Regressor** is a **continuous numerical value** ‚Äî specifically, the **average prediction** made by all the individual decision trees in the forest.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Explanation:\n",
    "\n",
    "1. For a given input $X$, each decision tree in the Random Forest makes its own prediction $y_i$.\n",
    "2. The final output is the **mean of all tree predictions**:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{N} \\sum_{i=1}^{N} y_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\hat{y}$ is the final predicted value,\n",
    "* $N$ is the number of trees in the forest,\n",
    "* $y_i$ is the prediction from the $i$-th tree.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "512d68f6-e1dd-4784-aa4f-5e1788138663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: -18.90547830189833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_regression(n_samples=100, n_features=4, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict for a single sample\n",
    "sample = X_test[0].reshape(1, -1)\n",
    "prediction = rf.predict(sample)\n",
    "print(\"Predicted value:\", prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622575dd-c939-4e0e-8c50-6717e90cb09d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Summary:\n",
    "\n",
    "* **The output of a Random Forest Regressor is a **single predicted numerical value** for each input, obtained by averaging the predictions of all the individual decision trees.***\n",
    "\n",
    "* **The predicted value of -18.905478 is the average of the predictions made by all the trees in the forest**.\n",
    "\n",
    "* **This can happen because the individual trees might have predicted negative values, and averaging these gives the final negative prediction**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d23766-7164-44db-8e97-8864bc6f8d5c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "\n",
    "### üìò Answer:\n",
    "\n",
    "No, the **Random Forest Regressor** is specifically designed for **regression tasks**, where the goal is to predict **continuous numerical values**. However, there is an equivalent model for **classification tasks** called the **Random Forest Classifier**.\n",
    "\n",
    "### üîç Differences Between Random Forest Regressor and Random Forest Classifier:\n",
    "\n",
    "* **Random Forest Regressor**: Used for predicting continuous values (e.g., predicting house prices, stock prices).\n",
    "\n",
    "  * The output is the **average** of the predictions made by each tree.\n",
    "* **Random Forest Classifier**: Used for predicting categorical labels (e.g., classifying emails as spam or not spam, diagnosing diseases based on symptoms).\n",
    "\n",
    "  * The output is determined by **majority voting** among all the decision trees, where the class predicted by the majority of trees becomes the final prediction.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Example of Using Random Forest for Classification:\n",
    "\n",
    "Here‚Äôs a quick example using **Random Forest Classifier** for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b146436d-8fae-4aa0-8d1d-a0bfee2adcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Iris dataset (classification task)\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392022cf-724a-406a-a237-a2d151426630",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Summary:\n",
    "\n",
    "* **Random Forest Regressor** is for **regression tasks** and predicts **continuous values**.\n",
    "* For **classification tasks**, you should use **Random Forest Classifier**, which outputs the predicted class based on majority voting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7087a21-85b4-49a2-b7d9-c0e65bb00161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
